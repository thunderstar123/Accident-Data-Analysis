{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the data from Excel file\n",
        "data = pd.read_csv('_annotations.csv')\n",
        "\n",
        "# Display the first few rows of the dataframe\n",
        "print(data.head())"
      ],
      "metadata": {
        "id": "arzkf9YERtDx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "230985be-fa8f-4c01-b363-d3dcafd28aad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                            filename  width  height   class  \\\n",
            "0  traffic_img1137_jpg.rf.3c89100f1b848e752675c2e...    640     640  severe   \n",
            "1  images_jpg.rf.3c44f7990f01238a95582330f4c6d4e0...    640     640  severe   \n",
            "2  Semi-RealisticVD-20_jpg.rf.3cbb4c9a36a57467c8f...    640     640  severe   \n",
            "3  Semi-RealisticVD-20_jpg.rf.3cbb4c9a36a57467c8f...    640     640  severe   \n",
            "4  sev11_jpg.rf.3c6908705e3752dc9cbdea964b3e1cfb.jpg    640     640  severe   \n",
            "\n",
            "   xmin  ymin  xmax  ymax  \n",
            "0   383     0   640   574  \n",
            "1   211   147   623   560  \n",
            "2   201   175   313   284  \n",
            "3   283   168   380   265  \n",
            "4   103    47   627   344  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def preprocess_image(file_name, target_size=(640, 640)):\n",
        "    image = cv2.imread(file_name)\n",
        "    image = cv2.resize(image, target_size)\n",
        "    image = image / 255.0  # Normalize pixel values to [0, 1]\n",
        "    return image\n",
        "\n",
        "# Apply preprocessing to each image\n",
        "images = [preprocess_image(f'path_to_images/{fname}') for fname in data['Name of the file']]\n",
        "images = np.array(images)\n",
        "\n",
        "# Prepare labels\n",
        "labels = data['severity of the accident'].values\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "h_kw9q4dtapR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(640, 640, 3)),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')  # Assuming binary classification for severity\n",
        "])\n"
      ],
      "metadata": {
        "id": "b-Mn74DitasY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "jTfBqKc_ta5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test), batch_size=32)\n"
      ],
      "metadata": {
        "id": "2r6oOdgZtjYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_video(video_path, model):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    predictions = []\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        preprocessed_frame = preprocess_image(frame)\n",
        "        prediction = model.predict(np.expand_dims(preprocessed_frame, axis=0))\n",
        "        predictions.append(prediction)\n",
        "\n",
        "    cap.release()\n",
        "    return predictions\n",
        "\n",
        "# Example usage\n",
        "video_predictions = process_video('path_to_video.mp4', model)\n"
      ],
      "metadata": {
        "id": "hPFVc30YtmDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming the Excel sheet has columns 'max_x', 'min_x', 'max_y', 'min_y' for bounding boxes\n",
        "bbox_data = data[['max_x', 'min_x', 'max_y', 'min_y']].values\n"
      ],
      "metadata": {
        "id": "IUFzMF2atm3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_video_with_bounding_boxes(video_path, model, bbox_data):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    out = None\n",
        "    frame_index = 0\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        preprocessed_frame = preprocess_image(frame)\n",
        "        prediction = model.predict(np.expand_dims(preprocessed_frame, axis=0))\n",
        "\n",
        "        if prediction[0][0] >= 0.5:  # Assuming a threshold of 0.5 for accident detection\n",
        "            bbox = bbox_data[frame_index]\n",
        "            cv2.rectangle(frame, (int(bbox[1]), int(bbox[3])), (int(bbox[0]), int(bbox[2])), (0, 255, 0), 2)\n",
        "\n",
        "        if out is None:\n",
        "            # Initialize video writer\n",
        "            fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "            out = cv2.VideoWriter('output_video.avi', fourcc, 20.0, (frame.shape[1], frame.shape[0]))\n",
        "\n",
        "        out.write(frame)\n",
        "        frame_index += 1\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "\n",
        "# Example usage\n",
        "process_video_with_bounding_boxes('path_to_video.mp4', model, bbox_data)\n"
      ],
      "metadata": {
        "id": "6nEFOxk0tpsu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Jd5uxLfxtrPR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}